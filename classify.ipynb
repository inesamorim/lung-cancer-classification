{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold, RandomizedSearchCV, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer, precision_score, f1_score, RocCurveDisplay, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and merge CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Scan_ID</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Texture</th>\n",
       "      <th>Spiculation</th>\n",
       "      <th>Lobulation</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Sphericity</th>\n",
       "      <th>Calcification</th>\n",
       "      <th>Internal Structure</th>\n",
       "      <th>Subtlety</th>\n",
       "      <th>Malignancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>LIDC-IDRI-0078</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LIDC-IDRI-0078</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>LIDC-IDRI-0078</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>LIDC-IDRI-0078</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>LIDC-IDRI-0069</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>6850</td>\n",
       "      <td>1016</td>\n",
       "      <td>LIDC-IDRI-0639</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>6851</td>\n",
       "      <td>1016</td>\n",
       "      <td>LIDC-IDRI-0639</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>6856</td>\n",
       "      <td>1017</td>\n",
       "      <td>LIDC-IDRI-0638</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>6855</td>\n",
       "      <td>1017</td>\n",
       "      <td>LIDC-IDRI-0638</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>6858</td>\n",
       "      <td>1018</td>\n",
       "      <td>LIDC-IDRI-0127</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2661 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Scan_ID      Patient_ID  Texture  Spiculation  Lobulation  Margin  \\\n",
       "0        2        1  LIDC-IDRI-0078        5            2           2       3   \n",
       "1        1        1  LIDC-IDRI-0078        4            2           3       3   \n",
       "2        8        1  LIDC-IDRI-0078        5            1           1       5   \n",
       "3        3        1  LIDC-IDRI-0078        5            3           3       3   \n",
       "4       16        2  LIDC-IDRI-0069        5            4           4       4   \n",
       "...    ...      ...             ...      ...          ...         ...     ...   \n",
       "2656  6850     1016  LIDC-IDRI-0639        3            3           2       2   \n",
       "2657  6851     1016  LIDC-IDRI-0639        1            2           1       2   \n",
       "2658  6856     1017  LIDC-IDRI-0638        5            1           2       4   \n",
       "2659  6855     1017  LIDC-IDRI-0638        5            1           1       5   \n",
       "2660  6858     1018  LIDC-IDRI-0127        5            3           3       5   \n",
       "\n",
       "      Sphericity  Calcification  Internal Structure  Subtlety  Malignancy  \n",
       "0              4              6                   1         4           4  \n",
       "1              4              6                   1         5           4  \n",
       "2              5              5                   1         4           1  \n",
       "3              4              5                   1         5           4  \n",
       "4              4              6                   1         2           3  \n",
       "...          ...            ...                 ...       ...         ...  \n",
       "2656           4              6                   1         4           4  \n",
       "2657           4              6                   1         2           4  \n",
       "2658           4              6                   1         3           4  \n",
       "2659           4              6                   1         5           2  \n",
       "2660           5              4                   1         5           2  \n",
       "\n",
       "[2661 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to merge CSV files\n",
    "def merge_csvs(csv_list):\n",
    "    # Load the first CSV\n",
    "    merged_df = pd.read_csv(csv_list[0], index_col=0)\n",
    "    \n",
    "    # Merge the remaining CSVs\n",
    "    for csv in csv_list[1:]:\n",
    "        temp_df = pd.read_csv(csv)\n",
    "        merged_df = merged_df.merge(temp_df, on=\"id\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "merged_df = merge_csvs([\"annotations_ds.csv\"])#, \"cnn.csv\"\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common pitfalls when evaluating and testing a classification model for potential lung nodule malignancy is not considering the nodules of the same patient to be completely separated into the training set or the validation set [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without stratify\n",
    "def foo(df):\n",
    "    # Step 1: Get unique patient_ids\n",
    "    unique_patients = df['patient_id'].unique()\n",
    "\n",
    "    # Step 2: Split unique patient_ids\n",
    "    train_patients, test_patients = train_test_split(unique_patients, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 3: Filter original dataset based on the split patient_ids\n",
    "    train_set = df[df['patient_id'].isin(train_patients)]\n",
    "    test_set = df[df['patient_id'].isin(test_patients)]\n",
    "\n",
    "# With stratify\n",
    "# TODO: Broken\n",
    "# malignancy isnt the same within the same group\n",
    "def split_dataset(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # Step 1: Aggregate to keep only one row per patient\n",
    "    grouped_df = df.groupby('Patient_ID').first().reset_index()\n",
    "\n",
    "    # Step 2: Split unique patient_ids with stratification\n",
    "    train_patients, test_patients = train_test_split(\n",
    "        grouped_df['Patient_ID'],\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=grouped_df['Malignancy']  # Stratify based on the class\n",
    "    )\n",
    "\n",
    "    # Step 3: Filter the original dataset based on the split patient_ids\n",
    "    train_set = df[df['Patient_ID'].isin(train_patients)]\n",
    "    test_set = df[df['Patient_ID'].isin(test_patients)]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44901/1736287427.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df[\"Malignancy\"] < 3] = 0\n",
      "/tmp/ipykernel_44901/1736287427.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df[merged_df[\"Malignancy\"] > 3] = 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m merged_df[merged_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMalignancy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m merged_df[merged_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMalignancy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 5\u001b[0m train_set, test_set \u001b[38;5;241m=\u001b[39m \u001b[43msplit_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Define features and target\u001b[39;00m\n\u001b[1;32m      8\u001b[0m X_train \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScan_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMalignancy\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# Exclude \"ID\", \"Scan_ID\", \"Patient_ID\" and \"Malignancy\" from features\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36msplit_dataset\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfirst()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 2: Split unique patient_ids with stratification\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_patients, test_patients \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrouped_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPatient_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrouped_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMalignancy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Stratify based on the class\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Step 3: Filter the original dataset based on the split patient_ids\u001b[39;00m\n\u001b[1;32m     14\u001b[0m train_set \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPatient_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(train_patients)]\n",
      "File \u001b[0;32m~/Documents/Escola/Universidade/3Âº Ano/1_sem/lab_ia/trab1/lung-cancer-classification/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Escola/Universidade/3Âº Ano/1_sem/lab_ia/trab1/lung-cancer-classification/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2806\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2802\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2804\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2806\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2808\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2811\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2812\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2813\u001b[0m     )\n\u001b[1;32m   2814\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Escola/Universidade/3Âº Ano/1_sem/lab_ia/trab1/lung-cancer-classification/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:1843\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1814\u001b[0m \n\u001b[1;32m   1815\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1842\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m-> 1843\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m~/Documents/Escola/Universidade/3Âº Ano/1_sem/lab_ia/trab1/lung-cancer-classification/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2252\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2250\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 2252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2257\u001b[0m     )\n\u001b[1;32m   2259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2261\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[1;32m   2263\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "merged_df = merged_df[merged_df[\"Malignancy\"]!=3] # Remove Indeterminate malignancy\n",
    "merged_df[merged_df[\"Malignancy\"] < 3] = 0\n",
    "merged_df[merged_df[\"Malignancy\"] > 3] = 1\n",
    "\n",
    "train_set, test_set = split_dataset(merged_df)\n",
    "\n",
    "# Define features and target\n",
    "X_train = merged_df.drop(columns=[\"ID\", \"Scan_ID\", \"Patient_ID\", \"Malignancy\"])  # Exclude \"ID\", \"Scan_ID\", \"Patient_ID\" and \"Malignancy\" from features\n",
    "y_train = merged_df[\"Malignancy\"]  # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the **RandomizedSearchCV** method, that allows for randomized sampling of hyperparameters to optimize the machine learning method.\n",
    "The function accepts a classifier, a set of hyperparameter distributions to search over, the input data X and labels y, and a name for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Preprocessing:** We created a **ColumnTransformer**, which applies **StandardScaler()** to scale the numeric features. This is crucial, especially for algorithms sensitive to feature scaling like XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Pipeline Setup:** We created a pipeline that consists of the preprocessing step and the classifying step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Cross-Validation:** We used **StratifiedKFold** cross-validation, which splits the data into 5 folds while ensuring that the distribution of classes remains balanced in each fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **RandomizedSearchCV:** The next step is to perform hyperparameter tuning by randomly selecting hyperparameter combinations from the provided **param_distributions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Fitting the Model and Displaying Results:** After the tuning process and the fitting of each model, the function prints the best hyperparameters and the highest AUC score achieved during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform RandomizedSearchCV\n",
    "def tune_model(classifier, param_distributions, X, y, group, model_name):\n",
    "    # Define the preprocessor (if needed)\n",
    "    # Here, we\"ll standardize the numeric features\n",
    "    numeric_features = X.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), numeric_features)  # Standardize numeric features\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),  # Preprocessing step\n",
    "        (\"classifier\", classifier)  # Classifier passed as parameter\n",
    "    ])\n",
    "\n",
    "    # Setup StratifiedKFold cross-validation\n",
    "    kf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Setup RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions,\n",
    "        n_iter=50,  # Number of random combinations to try\n",
    "        scoring=\"roc_auc\",  # Use AUC as the scoring metric\n",
    "        cv=kf,\n",
    "        random_state=42,\n",
    "        n_jobs=1,  # Use all available cores\n",
    "        return_train_score=True,\n",
    "        error_score='raise',\n",
    "    )\n",
    "\n",
    "    # Perform RandomizedSearchCV\n",
    "    random_search.fit(X, y, group=group)\n",
    "\n",
    "    # Display the best parameters and score\n",
    "    print(f\"{model_name} - Best parameters: {random_search.best_params_}\")\n",
    "    print(f\"{model_name} - Best AUC score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "    return random_search.best_estimator_, random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XGBoost (xgb_param_distributions): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **n_estimators:** Number of boosting rounds or trees to grow, with values ranging from 50 to 300 in steps of 50.\n",
    "- **max_depth:** Maximum depth of each tree, which controls the complexity of the model, sampled between 3 and 15.\n",
    "- **learning_rate:** The step size at each iteration, ranging from 0.01 to 0.2 to control the contribution of each tree.\n",
    "- **subsample:** Fraction of samples to be used in each boosting round, with values of 0.5, 0.7, and 1.0.\n",
    "- **colsample_bytree:** Fraction of features used when building each tree, with values of 0.5, 0.7, and 1.0.\n",
    "- **gamma:** Minimum loss reduction required to make a further partition in a leaf node, ranging from 0 to 5 in steps of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniela\\AppData\\Local\\Temp\\ipykernel_5596\\3633820395.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train[y_train>3] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Best parameters: {'classifier__subsample': 0.7, 'classifier__n_estimators': 200, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.1, 'classifier__gamma': 2.0, 'classifier__colsample_bytree': 0.7}\n",
      "XGBoost - Best AUC score: 0.9329\n",
      "Random Forest - Best parameters: {'classifier__n_estimators': 150, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 11}\n",
      "Random Forest - Best AUC score: 0.9285\n"
     ]
    }
   ],
   "source": [
    "# Parameter distributions for each classifier\n",
    "xgb_param_distributions = {\n",
    "    \"classifier__n_estimators\": np.arange(50, 300, 50),\n",
    "    \"classifier__max_depth\": np.arange(3, 15),\n",
    "    \"classifier__learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"classifier__subsample\": [0.5, 0.7, 1.0],\n",
    "    \"classifier__colsample_bytree\": [0.5, 0.7, 1.0],\n",
    "    \"classifier__gamma\": np.arange(0, 5, 0.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (rf_param_distributions):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **n_estimators:** Number of trees in the forest, sampled between 50 and 300 in steps of 50.\n",
    "- **max_depth:** Maximum depth of each tree, sampled between 3 and 15.\n",
    "- **min_samples_split:** Minimum number of samples required to split an internal node, with options of 2, 5, and 10.\n",
    "- **min_samples_leaf:** Minimum number of samples required to be at a leaf node, with values of 1, 2, and 4.\n",
    "- **max_features:** The number of features to consider when looking for the best split, with options \"auto\" and \"sqrt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_distributions = {\n",
    "    \"classifier__n_estimators\": np.arange(50, 300, 50),\n",
    "    \"classifier__max_depth\": np.arange(3, 15),\n",
    "    \"classifier__min_samples_split\": [2, 5, 10],\n",
    "    \"classifier__min_samples_leaf\": [1, 2, 4],\n",
    "    \"classifier__max_features\": [\"log2\", \"sqrt\"],\n",
    "}\n",
    "\n",
    "\n",
    "''' \n",
    "3 Ã© irrelevante , remove\n",
    "1Âª-> 1+2 bom, 4+5 mau                 corta-se max(1+2, 4+5)-min(1+2,4+5) a max(1+2,4+5)\n",
    "2Âª-> 1*0.5+2*0.5 bom, 4*0.5+5*0.5 mau\n",
    "3Âª-> w1, w2, w4, w5 \n",
    "4Âª-> >=3 mau, else bom\n",
    "\n",
    "  ver diferÃªnÃ§as entre as diff formas\n",
    "\n",
    "\n",
    "sendo 1, 5 os resultados mais seguros dar mais importÃ¢ncia q o 2, 4\n",
    "r => nÂº de nodulos malig/benig\n",
    "'''\n",
    "\n",
    "# Tune models\n",
    "best_xgb_model, best_xgb_params = tune_model(XGBClassifier(eval_metric=\"mlogloss\"), xgb_param_distributions, X_train, y_train, \"XGBoost\")\n",
    "best_rf_model, best_rf_params = tune_model(RandomForestClassifier(random_state=42), rf_param_distributions, X_train, y_train, \"Random Forest\")\n",
    "# TODO: SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9192\n",
      "Precision: 0.8513 Â± 0.0384\n",
      "F1-score: 0.8506 Â± 0.0380\n"
     ]
    }
   ],
   "source": [
    "''' FAZER PLOT DE RESULTADOS\n",
    "bACC\n",
    "F1,... vÃ¡rias mÃ©tricas(sÃ³ ACC Ã© proibido) \n",
    "\n",
    "para treino extra pontos para alterar pesos em vez de nÂº de exemplos\n",
    "'''\n",
    "\n",
    "models = [\n",
    "    (\"XgBoost\", best_xgb_model),\n",
    "    (\"Random Forest\", best_rf_model),\n",
    "]\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "for name, pipeline in models:\n",
    "    RocCurveDisplay.from_estimator(pipeline, X_test, y_test, ax=ax, name=name)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()\n",
    "\n",
    "names = []\n",
    "precisions = []\n",
    "f1_scores = []\n",
    "aucs = []\n",
    "for name, pipeline in models:\n",
    "    names.append(name)\n",
    "    precisions.append(precision_score(y_test, pipeline.predict(X_test)))\n",
    "    f1_scores.append(f1_score(y_test, best_rf_model.predict(X_test)))\n",
    "    aucs.append(roc_auc_score(y_test, best_xgb_model.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "\n",
    "plt.bar(names, precisions)\n",
    "plt.ylabel(\"scale\")\n",
    "plt.title(\"Precision\")\n",
    "plt.ylim(bottom=0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(names, f1_scores)\n",
    "plt.ylabel(\"scale\")\n",
    "plt.title(\"F1 Score\")\n",
    "plt.ylim(bottom=0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(names, aucs)\n",
    "plt.ylabel(\"scale\")\n",
    "plt.title(\"AUC Score\")\n",
    "plt.ylim(bottom=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] Causey, J.L., Zhang, J., Ma, S., Jiang, B., Qualls, J.A., Politte, D.G., Prior, F., Zhang, S. and Huang, X. (2018). Highly accurate model for prediction of lung nodule malignancy with CT scans. Scientific Reports, 8(1). doi:https://doi.org/10.1038/s41598-018-27569-w."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
